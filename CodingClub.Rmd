---
title: "Effects of Visual Feedback on Implicit and Explicit Adaptation"
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

# Pre-amble

When people make reaches they use many signals to determine where their hand is. This includes efferent-based predictions of hand location as well as afferent proprioceptive signals. Based on context people will rely more on predictions, and efferent signals to determine where their hand is. Here we trained people in the same perturbation with different types of information about the rotation. We test their explicit strategies to gauge if these contexts had effect on learning and then compare active and passive hand localization which respectively do or do not include efferent information. We expect groups with more explicit adaptation to rely on predictions more in their hand localization.

## Setup

Before any other steps, we make sure the machine is ready to run the code for the project. We install dependencies, and download the data.

The R environment for the is project is recorded in the renv.lock file that is part of this project. The code for `renv` itself should have been activated when opening the .Rprofile associated with this R Studio project, since it's embedded in the project. This should allow you to restore the exact set of packages used for this project.

**This chunk does not run automatically because it can be very time consuming. Run it manually to restore the R environment:**

```{r eval=F}
renv::restore()
```

Some of the code uses functions from our lab's `Reach` package which is not on an official package server, but can be installed from GitHub, using `remotes`.

**We do that below, but this chunk does not run by default since it's not necssary. Run manually to install the package.**

```{r eval=F}
library('remotes')
ip <- installed.packages()
if ('Reach' %in% ip[,'Package']) {
  if (ip[which(ip[,'Package'] == 'Reach'),'Version'] < "2025.02.16") {
    remotes::install_github('thartbm/Reach')
  }
} else {
  remotes::install_github('thartbm/Reach')
}
```

Finally, we have written some custom functions for this project, that we want available as well:

```{r}
# download and handle data:
source('R/data.R')
# scripts for training reaches:
source('R/reaches.R')
# scripts for figures:
source('R/figures.R')
# scripts for statistics:
source('R/statistics.R')
# scripts for exponentials:
source('R/exponentials.R')
```

### Download data

Up to now, we prepared the machine by getting code ready. The first bit of code we run downloads the data, which is perhaps also a step in getting the machine ready for useful stuff. The data is stored on this OSF repository: [SMCL coding club](https://osf.io/m5dt4/).

**The code below does not run by default, to reduce traffic to OSF.io. Run the chunk manually to download the data.**

```{r eval=F}
getData()
```

# Overview of experiment and data

In this experiment participants adapted to a 30 degree rotation, with various kinds of feedback:

1. Regular cursor feedback: "control"
2. Cursorjump feedback, where the rotation is shown at 1/3rd the reach on each training trial: "cursorjump"
3. A group where both the cursor and hand were visible during training: "handview"
4. A group that was explained the rotation beforehand: "instructed" (we're not using this group here)

All reaches were to targets at 45, 90 and 135 degrees.

## Data

There are several kind of data the we could analyse:

1. Training reaches
2. No-cursor reaches
3. Passive localization
4. Active localization

Both collected in the aligned and rotated phase of the task. With repetitions of each. See illustration below.

![Schedule of task order for all conditions.](doc/explicit_task_order.png){width=100%}


## Analysis plan

We want to know if the effect of efference copies on hand localization decreases when perturbations are more externally attributed (or perhaps when there is a larger explicit strategy).

### Training

Although not the main variable of interest, we do need to first check the training data:

- Did participants learn? Maybe we exclude some. If there is no learning, we do not get any hand localization shifts either, or at least we can't rely on them.
- Did all groups learn to the same extent? If they do, we can directly compare the size of other variables as well, if not, we'll have to rethink the rest of the analyses.
- Did all groups learn equally quickly? Perhaps this is not that important for our main questions, but it might be interesting to check.

### No-cursors

The manipulations might have an effect on implicit adaptation, here measured as without strategy no-cursor reach deviations. They should have an effect on explicit adaptation, which is only indirectly available in this project as the difference between with and without strategy no-cursor reach deviations.

- How do without-strategy no-cursor reach deviations vary with condition? If they do, there is an effect on implicit adaptation.
- Are there differences between with- and without strategy no-cursor reach deviations? Where we find any such difference, there is definitely a strategy.
- We will - for this example project - use the difference between the two kinds of no-cursor reach deviation as an estimate of explicit strategy, even though we do not really agree with this measure anymore. How does that look in each condition?

### Hand localization

Here we come to the main questions. We know that visuomotor adaptation also changes where we estimate the location of our hand within the workspace. We've shown before that there is a difference between active and passive hand localization. Active hand localization depends on predictions using an efference signal. These predictions may change depending on how we learn to adapt. For example, when adaptation more explicit or more externally attributed (or likely both, in the cursorjump and handview groups as compared to the control group). If hand localization is an implicit process, then the absence or presence of a strategy alone might not affect the predictions we (unconsciously) make, and active localization could still have increased hand localization shifts whether or not there is a strategy. However, external error attribution may (will) also occur implicitly if it is clear enough, along with explicit strategies. Nevertheless, in that case, predictions may not be based on efferent signals regardless of whether they were available.

To investigate all of this, we do several checks and tests. 

- Is there a difference between active and passive localization? At least in some of the groups there should be, e.g. in the control group.
- Is this different in the different conditions? Do some conditions (cursorjump, handview) not show a difference between active and passive hand localization shifts.
- Can this potentially be explained by different levels of explicit adaptation in the different conditions? Or potentially by external error attribution?

# Reach Training

## Reach deviations

In order to calculate a reach deviation, we can use the `atan2()` function, which takes a Y and X coordinate (note the order!), and returns the angle of a line going from the origin of the coordinate system (0,0) to the point (X,Y) in radians. The issue with this function is that its' output switches from $+\pi$ to $-\pi$ exactly to the left of the origin of the coordinate system. So a small change in position, gives almost the maximum change in direction. Especially if we have targets close to this switch point, then even with accurate reaches, performance could seem to be extremely bad. We need a solution to this.

In order to avoid this "switch-point" in the output, we rotate reach samples (either the whole trajectory, or single points on the reach, whatever we're working with) by -1 times the direction of the target. All reaches can then be seen as if the target were at 0Â°. And applying `atan2()` to such rotated trajectories, immediately gives the deviation from the target, so no further steps are necessary.

This rotation is most easily achieved by multiplying the trajectory samples with a [rotation matrix](https://en.wikipedia.org/wiki/Rotation_matrix) $R$. This is handled in the `getReachDeviation()` function, that's defined in the file `R\reaches.R`.

First we, need to convert the target angle (usually stored in degrees) to radians:

$$ \theta = \pi(-target/180) $$

Then we can use that to construct $R$:

$$ R = \begin{bmatrix}
cos(\theta) & -sin(\theta) \\
sin(\theta) & cos(\theta) \\
\end{bmatrix} $$

We get our set of trajectory samples, a vector $v$:

$$v = \begin{bmatrix}
x \\
y \\
\end{bmatrix} $$

And multiply it with the rotation matrix:

$$\bar{v} = Rv $$
This new vector $\bar{v}$ now contains the rotated trajectory samples, and we can apply `atan2()` to them.

> Note that $x$ and $y$ can be vectors, such that $v$ and $\bar{v}$ are not column matrices, but rectangular. This can be used to optimize the code for speed. You would first select a sample from each reach with the same target, add the coordinates to a matrix. Then multiply all of them with the same rotation matrix. This means that you only construct the rotation matrix for each target once, and all the matrix multiplication is done at the same time - with fewer loops, and less time spent in R interpretation. The code will be more complicated though, so we will not do this here.


Using all the math above, we will now calculate learning curves: the reach deviations relative to the target (in degrees angle) for every participant in the first 90 trials.

```{r}
getAllTraining()
```

This creates a file in each group's data directory with each participants' reach deviations at/beyond 2.5 cm for the first 90 rotated training trials, corrected for baseline. This can be used to analyse adaptation.

We plot the average within each group, as well as a 95% confidence interval:

```{r fig.width=8, fig.height=6}
plotTraining()
```

## Statistics

Let's do a mixed-design ANOVA on reach deviation, using block (trials: 1-3, 4-6, and 76-90) and group (control, cursorjump and handview) as factors.

```{r}
learningCurveANOVA()
```

As expected, there is a main effect of block (F(1.85,120.50)=83.78, p<.001). There is no effect of group nor an interaction.

To confirm there are no differences in the asymptotic levels of learning between the groups, we do a Bayesian analysis on the extent of learning (block 3 from above, trials 76-90):

```{r}
learningCurveBayes()
```

This means there is no evidence for or against an different extent of learning between the groups.

## Exponential fits

There is another way to look at these learning curves, and that is to fit an exponential (decay of error) function to the whole series (to reduce noise). Here we bootstrap the parameters for these functions separately for each group. This may take a while...

```{r}
bootstrapExponentials()
```

Now we can plot these bootstrapped exponential curves, fit to the learning curve data in each group:

```{r fig.width=8, fig.height=6}
plotFittedExponentials()
```

Perhaps there control group learns a bit slower than the other groups. Let's check the 95% Confidence Intervals.

```{r}
analyseExponentials()
```

So yes, the control group learns a little slower than the other two groups.

Let's zoom into the asymptotes:

```{r fig.width=5, fig.height=5}
plotAsymptotes()
```

The asymptotes do not seem different from each other, but there may be a difference with the bootstrapped version.

Let's check the learning rates:


```{r fig.width=5, fig.height=5}
plotLearningRates()
```

Plotted this way, the difference in learning rates that we saw earlier might not be that impactful.

We can also plot all of these in one multi-panel figure, that would be suitable for a journal publication, or maybe a thesis. This function calls all four other functions, and makes sure that the four figures end up in a nice plot. For the exponential fits, it only shows the first 30 trials. To do this we added an argument to the plotting function that by default plots the same figure we had before, or narrows down the range of trials.

```{r fig.width=8, fig.height=6}
fig2_learning()
```

*Training Results*:

1. There may or may not be a small difference in the rate of learning: the people in the control group might learn a little slower than those in the other two groups. The control group had the least amount of information about the rotation, so that could make sense, but it doesn't show up in all approaches.
2. The asymptotic level of adaptation is similar in all groups.

Since the research questions are about differences in implicit and explicit adaptation in reach aftereffects, and potentially efferent and afferent contributions to hand localization. So we do not need group differences in the training task. In fact, strong differences (especially in the asymptotes) would make subsequent analyses harder. So for now, we accept that there are no consequential differences in training. That means we can analyze the no-cursor data without further restrictions.

# No-cursor reaches

There are two kinds no-cursor reach blocks: with and without strategy. Without strategy is supposed to measure classic implicit adaptation, while with strategy is supposed to capture both implicit and explicit adaptation. Originally we used Process Dissociation Procedure to separate implicit and explicit adaptation:

- implicit: without-strategy no-cursor reaches
- explicit: with-strategy no-cursor reaches minus the without-strategy no-cursor reaches

However, this is not used anymore in the field.

We will use all of the no-cursor reach deviations. Baseline both the with and without strategy no-cursors using the aligned data. As with the reach training data, we also create one file per group that has no-cursor reach deviations for every participant, calculated the same way as for the training reaches.

```{r}
getAllNoCursors()
```

Then plot the group averages with confidence intervals, and the individual data. The design of this plot is based on what was in the original paper.

```{r}
plotNoCursors()
```
So it seems there is an effect of using a strategy in the no-cursor reaches, except in the control group. Let's test this. First with an ANOVA, with post-hoc follow-ups:

```{r}
doNoCursorANOVA()
```

We first verified that there is no effect of strategy use in the control group. Then we compared the two groups that seem to have a strategy with the control group, within the with and without strategy no-cursor reach deviations. And potentially compare these two groups with each other as well, in the no-strategy case. So there will be 6 post-hoc comparisons.

First, there is no effect of strategy use in the control group. This means, we can use it to see if strategies were evoked in the other two groups.

Comparing the handview and cursorjump group with-strategy no cursor reaches with those in the control group, shows a difference in both cases. This means that in these two groups there were explicit strategies.

Then, the cursorjump group does not have significantly lower reach deviations in the without-strategy no-cursor blocks as compared to the control group. That means the implicit adaptation is not different between these two groups.

The handview group has a difference in the without strategy no-cursor reaches with both the control group and the cursorjump group. This means that implicit adaptation is lower in this group as compared to others.

*No-cursor Results*:

1. With more information about the rotation in the visual feedback (cursorjump and handview groups) it seems that the amount of explicit adaptation may increase. Which is probably not all that surprising.
2. However, at the same time, the amount of implicit adaptation might also decrease. This for sure happens in the handview group, but it's not significant in the cursorjump group. It might not be immediately clear why this would happen. However, participants can only adapt 30 degrees, and if a lot of adaptation is already explicit, there is less room for implicit adaptation. (This makes sense in the competition account of adaptation: Scott Albert et al., 2022.) 

# Plot all figures

```{r}

# implemented target options are:
# - pdf
# - png
# - tiff
# - svg

for (target in c('pdf', 'png')) {

  plotTraining(target=target)
  plotFittedExponentials(target=target)
  plotAsymptotes(target=target)
  plotLearningRates(target=target)
  plotNoCursors(target=target)
  
  fig2_learning(target=target)

}

```

